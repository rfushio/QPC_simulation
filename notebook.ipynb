{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Thomas-Fermi Simulation & Plot Notebook (Google Colab Version)\n",
    "\n",
    "This notebook combines the simulation (`main1_5.py`) with plotting utilities from `plot-code/` so that everything runs interactively in Google Colab.\n",
    "\n",
    "## Setup Instructions for Google Colab:\n",
    "\n",
    "1. **Upload your project folder** to Google Drive or directly to Colab\n",
    "2. **Mount Google Drive** (if using Drive) or upload files directly\n",
    "3. **Install required packages** (if not already installed)\n",
    "4. **Run the cells sequentially**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running in local environment\")\n",
    "\n",
    "# Mount Google Drive if in Colab\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Set the project root path - MODIFY THIS PATH to match your Google Drive structure\n",
    "    # Example: if your Thomas-Fermi folder is in \"My Drive/Projects/Thomas-Fermi/\"\n",
    "    PROJECT_ROOT = Path('/content/drive/MyDrive/Thomas-Fermi-Folder/Thomas-Fermi')\n",
    "    \n",
    "    # Alternative: Upload files directly to Colab (uncomment if not using Drive)\n",
    "    # from google.colab import files\n",
    "    # uploaded = files.upload()  # Upload your project as a zip file\n",
    "    # !unzip -q your_project.zip\n",
    "    # PROJECT_ROOT = Path('/content/Thomas-Fermi')\n",
    "    \n",
    "else:\n",
    "    # Local environment\n",
    "    PROJECT_ROOT = Path('.')\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Install required packages if in Colab\n",
    "if IN_COLAB:\n",
    "    import subprocess\n",
    "    subprocess.run(['pip', 'install', 'scipy', 'matplotlib', 'numpy'], check=True)\n",
    "\n",
    "# Core imports and dynamic plotting module loading\n",
    "import importlib.util, time, re, numpy as np\n",
    "from datetime import datetime\n",
    "from dataclasses import asdict\n",
    "\n",
    "# Import solver modules\n",
    "try:\n",
    "    from solvers.solver3_movie import SimulationConfig, ThomasFermiSolver\n",
    "    print(\"Successfully imported solver modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing solver modules: {e}\")\n",
    "    print(\"Make sure the project structure is correct and all files are present\")\n",
    "\n",
    "# Dynamically import all plotting scripts in plot-code/ so they can be used as\n",
    "# regular Python modules inside this notebook.\n",
    "plot_dir = PROJECT_ROOT / 'plot-code'\n",
    "loaded_modules = []\n",
    "if plot_dir.exists():\n",
    "    for script_path in plot_dir.glob('*.py'):\n",
    "        try:\n",
    "            spec = importlib.util.spec_from_file_location(script_path.stem, script_path)\n",
    "            if spec is not None and spec.loader is not None:\n",
    "                mod = importlib.util.module_from_spec(spec)\n",
    "                sys.modules[script_path.stem] = mod\n",
    "                spec.loader.exec_module(mod)\n",
    "                loaded_modules.append(script_path.stem)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {script_path.stem}: {e}\")\n",
    "    print(f\"Loaded plotting modules: {loaded_modules}\")\n",
    "else:\n",
    "    print(f\"plot-code directory not found at {plot_dir}\")\n",
    "\n",
    "# Verify data files exist\n",
    "data_files = [\n",
    "    PROJECT_ROOT / 'data/1-data/James2.txt',\n",
    "    PROJECT_ROOT / 'data/0-data/Exc_data_digitized.csv'\n",
    "]\n",
    "for data_file in data_files:\n",
    "    if data_file.exists():\n",
    "        print(f\"âœ“ Found: {data_file}\")\n",
    "    else:\n",
    "        print(f\"âœ— Missing: {data_file}\")\n",
    "        print(\"Please ensure all data files are uploaded to the correct location\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Run the simulation\n",
    "\n",
    "Execute the next cell to launch the same batch of simulations as in `main1_5.py`. You can change the parameters if desired. Note that multiprocessing is replaced by a simple sequential loop for reliability within Jupyter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User-configurable parameters (copied from main1_5.py) ---\n",
    "DESIRED_PAIRS = [\n",
    "    (-4.0, -1.50), (-3.70, -1.50), (-3.40, -1.50), (-3.10, -1.50),\n",
    "    (-2.80, -1.50), (-2.50, -1.50), (-2.20, -1.50), (-1.90, -1.50),\n",
    "    (-1.60, -1.50), (-1.30, -1.50), (-1.00, -1.50), (-0.70, -1.50),\n",
    "    (-0.40, -1.50), (-0.10, -1.50), (0.20, -1.50), (0.50, -1.50),\n",
    "    (0.80, -1.50), (1.10, -1.50), (1.40, -1.50), (1.70, -1.50),\n",
    "    (2.00, -1.50), (2.30, -1.50), (2.60, -1.50), (2.90, -1.50),\n",
    "    (3.20, -1.50), (3.50, -1.50), (3.80, -1.50)\n",
    "]\n",
    "\n",
    "GRID_N = 128\n",
    "\n",
    "# Optimiser parameters\n",
    "BASINHOPPING_NITER = 10\n",
    "BASINHOPPING_STEP_SIZE = 1.0\n",
    "LBFGS_MAXITER = 1000\n",
    "LBFGS_MAXFUN = 2000000\n",
    "\n",
    "# Potential offset / scaling (empirical)\n",
    "POTENTIAL_SCALE = 1.0\n",
    "POTENTIAL_OFFSET = 0.033  # V\n",
    "\n",
    "# Helper functions -------------------------------------------------------------\n",
    "\n",
    "def parse_header(james_path: Path):\n",
    "    \"\"\"Return mapping idx â†’ (V_QPC, V_SG) from metadata header.\"\"\"\n",
    "    header_lines = []\n",
    "    with james_path.open('r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            if not line.lstrip().startswith('%'):\n",
    "                break\n",
    "            header_lines.append(line.strip())\n",
    "    header_text = ' '.join(header_lines)\n",
    "    pat = re.compile(r\"@\\s*(\\d+):\\s*VQPC=([+-]?\\d*\\.?\\d+)\\s*V,\\s*VSG=([+-]?\\d*\\.?\\d+)\\s*V\", re.I)\n",
    "    mapping = {}\n",
    "    for m in pat.finditer(header_text):\n",
    "        mapping[int(m.group(1)) - 1] = (float(m.group(2)), float(m.group(3)))\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def run_single_simulation(idx, x_nm, y_nm, V_vals, pair, batch_dir):\n",
    "    \"\"\"Run one simulation (sequential version for notebooks).\"\"\"\n",
    "    cfg = SimulationConfig(\n",
    "        N=GRID_N,\n",
    "        potential_data=(x_nm, y_nm, V_vals),\n",
    "        niter=BASINHOPPING_NITER,\n",
    "        step_size=BASINHOPPING_STEP_SIZE,\n",
    "        lbfgs_maxiter=LBFGS_MAXITER,\n",
    "        lbfgs_maxfun=LBFGS_MAXFUN,\n",
    "        potential_scale=POTENTIAL_SCALE,\n",
    "        potential_offset=POTENTIAL_OFFSET,\n",
    "        exc_file=str(PROJECT_ROOT / 'data/0-data/Exc_data_digitized.csv'),\n",
    "        solver_type='solver3',\n",
    "    )\n",
    "\n",
    "    solver = ThomasFermiSolver(cfg)\n",
    "    pot_dir = batch_dir / f\"pot{idx}\"\n",
    "    pot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Save parameters\n",
    "    with (pot_dir / 'simulation_parameters.txt').open('w', encoding='utf-8') as f:\n",
    "        for k, v in asdict(cfg).items():\n",
    "            f.write(f\"{k} = {v}\\n\")\n",
    "\n",
    "    # 2) Run optimisation\n",
    "    t0 = time.time()\n",
    "    solver.optimise()\n",
    "    exec_sec = time.time() - t0\n",
    "\n",
    "    # 3) Save & plot\n",
    "    title_extra = f\"V_QPC={pair[0]:+.2f} V, V_SG={pair[1]:+.2f} V\"\n",
    "    solver.plot_results(save_dir=str(pot_dir), title_extra=title_extra, show=False)\n",
    "    solver.save_results(pot_dir)\n",
    "\n",
    "    with (pot_dir / 'simulation_parameters.txt').open('a', encoding='utf-8') as f:\n",
    "        f.write(\"\\n# Execution time\\n\")\n",
    "        f.write(f\"execution_time_seconds = {exec_sec:.6f}\\n\")\n",
    "        f.write(f\"execution_time_minutes = {exec_sec/60:.6f}\\n\")\n",
    "\n",
    "\n",
    "def run_batch():\n",
    "    \"\"\"Run the full batch of simulations defined in *DESIRED_PAIRS*.\"\"\"\n",
    "    # Load combined potential file using absolute path\n",
    "    data_file = PROJECT_ROOT / 'data/1-data/James2.txt'\n",
    "    data = np.loadtxt(str(data_file), comments='%')\n",
    "    mask = (\n",
    "        (data[:, 0] >= -150) & (data[:, 0] <= 150) &\n",
    "        (data[:, 1] >= -150) & (data[:, 1] <= 150)\n",
    "    )\n",
    "    x_nm = data[mask, 0]\n",
    "    y_nm = data[mask, 1]\n",
    "    V_columns = data[mask, 3:]\n",
    "\n",
    "    idx_to_vs = parse_header(data_file)\n",
    "\n",
    "    # Map requested pairs â†’ column indices\n",
    "    idxs = []\n",
    "    tol = 1e-6\n",
    "    for pair in DESIRED_PAIRS:\n",
    "        found = [i for i, vs in idx_to_vs.items() if abs(vs[0]-pair[0]) < tol and abs(vs[1]-pair[1]) < tol]\n",
    "        if not found:\n",
    "            raise ValueError(f\"Requested pair {pair} not found in header.\")\n",
    "        idxs.append(found[0])\n",
    "\n",
    "    # Prepare output directories - use absolute path\n",
    "    base_dir = PROJECT_ROOT / 'analysis_folder'\n",
    "    today = datetime.now().strftime('%Y%m%d')\n",
    "    date_dir = base_dir / today\n",
    "    date_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    batch_dir = date_dir / timestamp\n",
    "    batch_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Run sequential simulations\n",
    "    for idx in idxs:\n",
    "        V_vals = V_columns[:, idx]\n",
    "        pair = idx_to_vs[idx]\n",
    "        print(f\"Starting simulation idx={idx} pair={pair}\")\n",
    "        run_single_simulation(idx, x_nm, y_nm, V_vals, pair, batch_dir)\n",
    "        print(f\"Finished simulation idx={idx}\")\n",
    "\n",
    "    print(f\"All simulations complete. Results stored in {batch_dir}\")\n",
    "    return batch_dir\n",
    "\n",
    "# Uncomment the next line to run immediately\n",
    "# batch_dir = run_batch()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example: Plotting centre density map\n",
    "\n",
    "After you have `batch_dir` from `run_batch()`, you can create a 2-D map of centre density using the functions from `plot_density_center_2d.py`.\n",
    "\n",
    "```python\n",
    "import plot_density_center_2d as pmap\n",
    "pmap.plot_density_2d(batch_dir, Path('data/1-data/James2.txt'))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plot centre density map\n",
    "# Uncomment and modify the path below after running simulations\n",
    "# import plot_density_center_2d as pmap\n",
    "# run_dir = PROJECT_ROOT / 'analysis_folder/20250702/run_152740'  # Update with your actual run directory\n",
    "# james_file = PROJECT_ROOT / 'data/1-data/James2.txt'\n",
    "# pmap.plot_density_2d(run_dir, james_file)\n",
    "\n",
    "# Example: Plot linecuts\n",
    "# import plot_linecut_x as plx\n",
    "# results_file = PROJECT_ROOT / 'analysis_folder/20250702/run_152740/pot0/results.npz'  # Update path\n",
    "# plx.plot_x_linecut(results_file)\n",
    "\n",
    "# Example: Plot energy decrease  \n",
    "# import plot_energy_decrease as ped\n",
    "# results_file = PROJECT_ROOT / 'analysis_folder/20250702/run_152740/pot0/results.npz'  # Update path\n",
    "# ped.plot_energy_decrease(results_file)\n",
    "\n",
    "# Helper function to run simulations and create plots\n",
    "def run_and_plot():\n",
    "    \"\"\"Run simulations and create example plots.\"\"\"\n",
    "    # Run simulations\n",
    "    batch_dir = run_batch()\n",
    "    \n",
    "    # Create center density map\n",
    "    if 'plot_density_center_2d' in loaded_modules:\n",
    "        import plot_density_center_2d as pmap\n",
    "        james_file = PROJECT_ROOT / 'data/1-data/James2.txt'\n",
    "        pmap.plot_density_2d(batch_dir, james_file)\n",
    "    \n",
    "    # Create linecut for first simulation\n",
    "    pot_dirs = list(batch_dir.glob('pot*'))\n",
    "    if pot_dirs and 'plot_linecut_x' in loaded_modules:\n",
    "        import plot_linecut_x as plx\n",
    "        results_file = pot_dirs[0] / 'results.npz'\n",
    "        if results_file.exists():\n",
    "            plx.plot_x_linecut(results_file)\n",
    "    \n",
    "    return batch_dir\n",
    "\n",
    "# Uncomment to run simulations and plots automatically\n",
    "# batch_dir = run_and_plot()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Instructions for Google Colab Usage\n",
    "\n",
    "### Method 1: Using Google Drive\n",
    "\n",
    "1. **Upload your Thomas-Fermi project folder** to Google Drive\n",
    "2. **Modify the PROJECT_ROOT path** in the first code cell to match your Drive structure:\n",
    "   ```python\n",
    "   PROJECT_ROOT = Path('/content/drive/MyDrive/YourFolder/Thomas-Fermi')\n",
    "   ```\n",
    "3. **Run the cells** sequentially\n",
    "\n",
    "### Method 2: Direct Upload to Colab\n",
    "\n",
    "1. **Upload your project as a zip file** using the file browser in Colab\n",
    "2. **Uncomment the alternative setup** in the first code cell:\n",
    "   ```python\n",
    "   # from google.colab import files\n",
    "   # uploaded = files.upload()\n",
    "   # !unzip -q your_project.zip\n",
    "   # PROJECT_ROOT = Path('/content/Thomas-Fermi')\n",
    "   ```\n",
    "\n",
    "### Running Simulations\n",
    "\n",
    "- **Test run**: Uncomment `batch_dir = run_batch()` to run all simulations\n",
    "- **Quick test**: Modify `DESIRED_PAIRS` to include fewer pairs for faster testing\n",
    "- **Automatic plotting**: Use `batch_dir = run_and_plot()` to run simulations and create plots\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- **Runtime**: Full simulations may take several hours\n",
    "- **Memory**: Colab has memory limits - consider reducing `GRID_N` if needed\n",
    "- **Storage**: Results are saved to your Drive (Method 1) or temporary Colab storage (Method 2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Thomas-Fermi Simulation & Plot Notebook\n",
    "\n",
    "This notebook combines the simulation (`main1_5.py`) with plotting utilities from `plot-code/` so that everything runs interactively in Jupyter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports and dynamic plotting module loading\n",
    "import importlib.util, sys, time, re, numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dataclasses import asdict\n",
    "\n",
    "from solvers.solver3_movie import SimulationConfig, ThomasFermiSolver\n",
    "\n",
    "# Dynamically import all plotting scripts in plot-code/ so they can be used as\n",
    "# regular Python modules inside this notebook.\n",
    "plot_dir = Path('plot-code')\n",
    "loaded_modules = []\n",
    "for script_path in plot_dir.glob('*.py'):\n",
    "    spec = importlib.util.spec_from_file_location(script_path.stem, script_path)\n",
    "    if spec is not None and spec.loader is not None:\n",
    "        mod = importlib.util.module_from_spec(spec)\n",
    "        sys.modules[script_path.stem] = mod\n",
    "        spec.loader.exec_module(mod)\n",
    "        loaded_modules.append(script_path.stem)\n",
    "print(f\"Loaded plotting modules: {loaded_modules}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Run the simulation\n",
    "\n",
    "Execute the next cell to launch the same batch of simulations as in `main1_5.py`. You can change the parameters if desired. Note that multiprocessing is replaced by a simple sequential loop for reliability within Jupyter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User-configurable parameters (copied from main1_5.py) ---\n",
    "DESIRED_PAIRS = [\n",
    "    (-4.0, -1.50), (-3.70, -1.50), (-3.40, -1.50), (-3.10, -1.50),\n",
    "    (-2.80, -1.50), (-2.50, -1.50), (-2.20, -1.50), (-1.90, -1.50),\n",
    "    (-1.60, -1.50), (-1.30, -1.50), (-1.00, -1.50), (-0.70, -1.50),\n",
    "    (-0.40, -1.50), (-0.10, -1.50), (0.20, -1.50), (0.50, -1.50),\n",
    "    (0.80, -1.50), (1.10, -1.50), (1.40, -1.50), (1.70, -1.50),\n",
    "    (2.00, -1.50), (2.30, -1.50), (2.60, -1.50), (2.90, -1.50),\n",
    "    (3.20, -1.50), (3.50, -1.50), (3.80, -1.50)\n",
    "]\n",
    "\n",
    "GRID_N = 128\n",
    "\n",
    "# Optimiser parameters\n",
    "BASINHOPPING_NITER = 10\n",
    "BASINHOPPING_STEP_SIZE = 1.0\n",
    "LBFGS_MAXITER = 1000\n",
    "LBFGS_MAXFUN = 2000000\n",
    "\n",
    "# Potential offset / scaling (empirical)\n",
    "POTENTIAL_SCALE = 1.0\n",
    "POTENTIAL_OFFSET = 0.033  # V\n",
    "\n",
    "# Helper functions -------------------------------------------------------------\n",
    "\n",
    "def parse_header(james_path: Path):\n",
    "    \"\"\"Return mapping idx â†’ (V_QPC, V_SG) from metadata header.\"\"\"\n",
    "    header_lines = []\n",
    "    with james_path.open('r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            if not line.lstrip().startswith('%'):\n",
    "                break\n",
    "            header_lines.append(line.strip())\n",
    "    header_text = ' '.join(header_lines)\n",
    "    pat = re.compile(r\"@\\s*(\\d+):\\s*VQPC=([+-]?\\d*\\.?\\d+)\\s*V,\\s*VSG=([+-]?\\d*\\.?\\d+)\\s*V\", re.I)\n",
    "    mapping = {}\n",
    "    for m in pat.finditer(header_text):\n",
    "        mapping[int(m.group(1)) - 1] = (float(m.group(2)), float(m.group(3)))\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def run_single_simulation(idx, x_nm, y_nm, V_vals, pair, batch_dir):\n",
    "    \"\"\"Run one simulation (sequential version for notebooks).\"\"\"\n",
    "    cfg = SimulationConfig(\n",
    "        N=GRID_N,\n",
    "        potential_data=(x_nm, y_nm, V_vals),\n",
    "        niter=BASINHOPPING_NITER,\n",
    "        step_size=BASINHOPPING_STEP_SIZE,\n",
    "        lbfgs_maxiter=LBFGS_MAXITER,\n",
    "        lbfgs_maxfun=LBFGS_MAXFUN,\n",
    "        potential_scale=POTENTIAL_SCALE,\n",
    "        potential_offset=POTENTIAL_OFFSET,\n",
    "        exc_file='data/0-data/Exc_data_digitized.csv',\n",
    "        solver_type='solver3',\n",
    "    )\n",
    "\n",
    "    solver = ThomasFermiSolver(cfg)\n",
    "    pot_dir = batch_dir / f\"pot{idx}\"\n",
    "    pot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Save parameters\n",
    "    with (pot_dir / 'simulation_parameters.txt').open('w', encoding='utf-8') as f:\n",
    "        for k, v in asdict(cfg).items():\n",
    "            f.write(f\"{k} = {v}\\n\")\n",
    "\n",
    "    # 2) Run optimisation\n",
    "    t0 = time.time()\n",
    "    solver.optimise()\n",
    "    exec_sec = time.time() - t0\n",
    "\n",
    "    # 3) Save & plot\n",
    "    title_extra = f\"V_QPC={pair[0]:+.2f} V, V_SG={pair[1]:+.2f} V\"\n",
    "    solver.plot_results(save_dir=str(pot_dir), title_extra=title_extra, show=False)\n",
    "    solver.save_results(pot_dir)\n",
    "\n",
    "    with (pot_dir / 'simulation_parameters.txt').open('a', encoding='utf-8') as f:\n",
    "        f.write(\"\\n# Execution time\\n\")\n",
    "        f.write(f\"execution_time_seconds = {exec_sec:.6f}\\n\")\n",
    "        f.write(f\"execution_time_minutes = {exec_sec/60:.6f}\\n\")\n",
    "\n",
    "\n",
    "def run_batch():\n",
    "    \"\"\"Run the full batch of simulations defined in *DESIRED_PAIRS*.\"\"\"\n",
    "    # Load combined potential file\n",
    "    data = np.loadtxt('data/1-data/James2.txt', comments='%')\n",
    "    mask = (\n",
    "        (data[:, 0] >= -150) & (data[:, 0] <= 150) &\n",
    "        (data[:, 1] >= -150) & (data[:, 1] <= 150)\n",
    "    )\n",
    "    x_nm = data[mask, 0]\n",
    "    y_nm = data[mask, 1]\n",
    "    V_columns = data[mask, 3:]\n",
    "\n",
    "    idx_to_vs = parse_header(Path('data/1-data/James2.txt'))\n",
    "\n",
    "    # Map requested pairs â†’ column indices\n",
    "    idxs = []\n",
    "    tol = 1e-6\n",
    "    for pair in DESIRED_PAIRS:\n",
    "        found = [i for i, vs in idx_to_vs.items() if abs(vs[0]-pair[0]) < tol and abs(vs[1]-pair[1]) < tol]\n",
    "        if not found:\n",
    "            raise ValueError(f\"Requested pair {pair} not found in header.\")\n",
    "        idxs.append(found[0])\n",
    "\n",
    "    # Prepare output directories\n",
    "    base_dir = Path('analysis_folder')\n",
    "    today = datetime.now().strftime('%Y%m%d')\n",
    "    date_dir = base_dir / today\n",
    "    date_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    batch_dir = date_dir / timestamp\n",
    "    batch_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Run sequential simulations\n",
    "    for idx in idxs:\n",
    "        V_vals = V_columns[:, idx]\n",
    "        pair = idx_to_vs[idx]\n",
    "        print(f\"Starting simulation idx={idx} pair={pair}\")\n",
    "        run_single_simulation(idx, x_nm, y_nm, V_vals, pair, batch_dir)\n",
    "        print(f\"Finished simulation idx={idx}\")\n",
    "\n",
    "    print(f\"All simulations complete. Results stored in {batch_dir}\")\n",
    "    return batch_dir\n",
    "\n",
    "# Uncomment the next line to run immediately\n",
    "# batch_dir = run_batch()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
